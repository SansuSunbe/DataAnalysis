# 17. 머신러닝

# 머신러닝

### 데이터에서 패턴을 학습하여 예측 또는 의사 결정을 자동화하는 알고리즘의 집합
사람의 개입 없이도 학습 데이터로부터 모델을 생성하고 이를 기반으로 새로운 데이터에 대한 결과를 예측한다.

## 특징

### 데이터 중심

- 많은 양의 데이터에서 통계적 패턴 학습

### 모델 학습

- 알고리즘이 데이터를 기반으로 모델을 자동 생성

### 자동화된 학습

- 입력된 데이터를 학습하여 결과를 지속적으로 개선 가능

## 지도 학습(Supervised Learning)

- 레이블이라는 정답을 포함한 데이터를 학습하여 새로운 데이터에 대한 결과를 예측

### 분류(Classification)

- 데이터를 이산적으로 카테고리로 분류

### 회귀(Regression)

- 연속적인 값 예측

### 작동 원리

- 모델은 입력 데이터(X)와 정답(Y)를 학습한다.
- 학습 후 새로운 데이터(X)에 대해 예측값(Y)를 제공한다.

## 비지도 학습(Unsupervised Learning)

- 레이블이 없는 데이터를 사용하여 데이터의 숨겨진 구조나 패턴을 학습

### 클러스터링(Clustering)

- 데이터를 유사한 그룹으로 묶음

### 차원 축소(Dimensionality Reduction)

- 고차원 데이터를 간소화

### 작동 원리

- 알고리즘은 데이터(X)만으로 군집화 또는 패턴을 발견한다.
- 데이터의 유사성을 기반으로 그룹을 정의 한다.

## 학습 데이터(Tranning Data)

- 모델 학습에 사용되는 데이터 셋, 입력데이터(X)와 결과값(Y)을 포함
- 모델이 입력과 결과 간의 관계를 학습하도록 도와줌

## 테스트 데이터(Test Data)

- 학습된 모델의 성능을 평가하기 위해 사용되는 데이터 셋
- 새로운 데이터에 대해 모델이 얼마나 정확히 예측하는지 평가

## 로지스틱 회귀

- 선형 회귀를 확장하여 확률을 예측하는 모델
- 이진 분류에 적합
    - 결과가 y = 0 또는 y = 1과 같은 이진값일 때 효과적
- 확률로 해석 가능
    - β0(베타0)와 β1(베타1)의 값으로 변수의 중요성과 영향을 이해할 수 있음

## 결정트리

- 데이터 분할 규칙을 트리구조로 표현한 모델
- 트리의 각 노드는 특정 조건(특징)을 기반으로 데이터를 나누고, 최종적으로 예측 값을 제공하는
잎(leaf) 노드에 따라 데이터를 조건에 따라 반복적으로 분할하여 학습

## 예시

```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

# 데이터 로드
iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)
print(X_train.shape)
print(y_train.shape)
print(X_test.shape)

# 모델 생성 및 학습
tree = DecisionTreeClassifier(max_depth=3, random_state=42)
tree.fit(X_train, y_train)

# 트리 시각화
plt.figure(figsize=(12, 8))
plot_tree(tree, feature_names=iris.feature_names, class_names=iris.target_names, filled=True)
plt.show()

# 모델 평가
accuracy = tree.score(X_test, y_test)
print(f"모델 정확도: {accuracy:.2f}")
```

## 모델 평가 지표

### TP(True Positive)

- 실제 정답이 True이고 모델이 True로 예측한 경우

### TN(True Negative)

- 실제 정답이 False이고 모델이 False로 예측한 경우

### FP(False Positive)

- 실제 정답이 False인데 모델이 True로 잘못 예측한 경우

### FN(False Negative)

- 실제 정답이 True인데 모델이 False로 잘못 예측한 경우

| Accuracy(정확도) | Precision(정밀도) | Recall(재현율) | F1 Score |
| --- | --- | --- | --- |
| 전체 데이터 중 맞춘 비율 | 예측 결과 중 실제로 True인 비율 | 실제 True 중 예측 성공 비율 | 정밀도와 재현율의 조화 평균 |
| (TP + TN) / (TP + TN + FP + FN) | TP / (TP + FP) | TP / (TP + FN) | (2 * Precision * Recall) / (Precision + Recall) |

## 예시 2

```python
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# 예제 데이터 (y_true: 실제값, y_pred: 예측값)
y_true = [1, 0, 1, 1, 0]
y_pred = [1, 0, 1, 0, 0]

# 평가 지표 계산
print("Accuracy:", accuracy_score(y_true, y_pred))
print("Precision:", precision_score(y_true, y_pred))
print("Recall:", recall_score(y_true, y_pred))
print("F1 Score:", f1_score(y_true, y_pred))
```