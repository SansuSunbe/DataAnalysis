# 23. 딥러닝

# 딥 러닝

### 다층 신경망을 기반으로 데이터를 학습하고 예측하는 머신러닝의 하위 분야

## 특징

- 대규모 데이터와 강력한 계산 자원 활용
- 이미지, 음성, 텍스트 등 다양한 비정형 데이터를 처리 가능

## 응용 분야

- 이미지 인식
- 자연어 처리
- 자율 주행

## 신경망의 기본 구성

### 뉴런(Neuron)

- 데이터 입력을 받아 가중치를 곱하고 활성화 함수를 통해 출력
- 공식
    - y = f(w₁x₁ + w₂x₂ + ... + b)
    - f : 활성화 함수
    - w : 가중치
    - b : 편향

### 계층(Layer)

- 입력층(Input Layer)
    - 데이터를 모델에 전달
- 은닉층(Hidden Layer)
    - 입력 데이터를 변환하여 패턴 학습
- 출력층(Output Layer)
    - 최종 예측 값 생성

### 활성화 함수(Activation Function)

- ReLU
    - f(x) = max(0, x) (비선형성 추가)
- Sigmoid
    - 확률 값 출력에 사용(0~1)

## 신경망의 작동 원리

### 순전파(Forward Propagation)

- 입력 데이터가 계층을 거쳐 예측 값 생성

### 손실 계산(Loss Function)

- 실제 값과 예측 값의 차이를 계산
- ex)
    - MSE, Cross-Entropy)

### 역전파(Backpropagation)

- 손실 값을 기반으로 가중치를 업데이트

### 최적화(Optimization)

- 경사 하강법(Gradient Descent)을 사용하여 모델 성능 개선

## 딥 러닝 모델의 학습 과정

### 1. 데이터 준비

- 학습 데이터와 테스트 데이터로 분할

### 2. 모델 학습

- 데이터로부터 가중치를 조정하여 학습

### 3. 성능 평가

- 테스트 데이터로 모델 성능 평가

## 예시

### 샘플 데이터 생성 및 모델 학습

```python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# 샘플 데이터 생성
import numpy as np
X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y = np.array([0, 1, 1, 0])  # XOR 문제
# XOR연산 특징 -> 동일한 값 출력 0 ex [0, 0], [1, 1]
# 다른 값 [0, 1], [1, 0] 출력 1

# 모델 생성
model = Sequential([
    Dense(4, input_dim=2, activation='relu'),  # 은닉층
    Dense(1, activation='sigmoid')  # 출력층
])

# 모델 컴파일
model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])

# 모델 학습
model.fit(X, y, epochs = 100, verbose = 1)
```

### 모델 평가 & 학습 결과

```python
# 모델 평가
loss, accuracy = model.evaluate(X, y)
print(f"Accuracy : {accuracy : .2f}")

# XOR 문제의 학습 결과 확인
forecast = model.predict(X)
print("Predicted values : ", forecast)
```

### 시각화

```python
from tensorflow.keras.utils import plot_model

# 모델 구조 시각화
plot_model(model, to_file='model_structure.png', show_shapes=True, show_layer_names=True)

import matplotlib.pyplot as plt

# 예측 값 계산
predictions = model.predict(X)

# 데이터 시각화
plt.figure(figsize=(8, 4))
plt.scatter(range(len(y)), y, color='blue', label='Actual', s=100) # 실제 값
plt.scatter(range(len(predictions)), predictions, color='red', label='Predicted', s=100) # 예측 값
plt.title("Actual vs Predicted Outputs")
plt.xlabel("Sample Index")
plt.ylabel("Output Value")
plt.legend()
plt.grid(True)
plt.show()

# 모델 학습 과정 저장
history = model.fit(X, y, epochs=100, verbose=1)

# 손실 값 변화 시각화
plt.figure(figsize=(8, 4))
plt.plot(history.history['loss'], label='Loss')
plt.title("Loss Over Epochs")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.grid(True)
plt.show()

import seaborn as sns
import numpy as np

# 은닉층의 가중치 가져오기
weights, biases = model.layers[0].get_weights()

# 가중치 시각화
plt.figure(figsize=(6, 4))
sns.heatmap(weights, annot=True, cmap="coolwarm", cbar=True)
plt.title("Weights of Hidden Layer")
plt.xlabel("Input Features")
plt.ylabel("Hidden Neurons")
plt.show()
```